{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloads files from EUMETSAT using HTTP.\n",
    "\n",
    "See the environment variable EUMETSAT_PASSWORD with your password :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import math\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import queue\n",
    "import threading\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from eumetsat import get_filesize_megabytes\n",
    "from consts import PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESTINATION_DIR = os.path.join(PATH, 'auto_downloads')\n",
    "LOG_DIR = os.path.join(PATH, 'logs/download')\n",
    "DOWNLOADED_FILES = os.path.join(DESTINATION_DIR, 'downloaded_files.csv')\n",
    "NUM_WORKER_THREADS = 5\n",
    "\n",
    "for directory in [DESTINATION_DIR, LOG_DIR]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "## Logging\n",
    "STREAM_HANDLER = True\n",
    "LOG_FILENAME = os.path.join(LOG_DIR, 'eumetsat_download.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger('eumetsat_download')\n",
    "log.setLevel(logging.DEBUG)\n",
    "log.handlers = [logging.FileHandler(filename=LOG_FILENAME, mode='a')]\n",
    "if STREAM_HANDLER:\n",
    "    log.handlers.append(logging.StreamHandler(sys.stdout))\n",
    "formatter = logging.Formatter(\n",
    "    '%(asctime)s - %(name)s - %(threadName)s - %(levelname)s - %(message)s')\n",
    "for handler in log.handlers:\n",
    "    handler.setFormatter(formatter)\n",
    "\n",
    "# Attach urllib3's logger to our logger.\n",
    "loggers_to_attach = ['urllib3', 'requests']\n",
    "for logger_name_to_attach in loggers_to_attach:\n",
    "    logger_to_attach = logging.getLogger(logger_name_to_attach)\n",
    "    logger_to_attach.parent = log\n",
    "    logger_to_attach.propagate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_dir(base_url):\n",
    "    \"\"\"Recursively searches through directories to find accepted files.\n",
    "    \n",
    "    Return dict mapping from filename to filesize in megabytes (if available).\n",
    "    \"\"\"\n",
    "    page = requests.get(base_url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "    # Filesizes for the .tar files are available on the eumetsat website.  These filesizes\n",
    "    # can be identified by the 'align=right' attribute.\n",
    "    file_sizes_mb = soup.find_all(align='right')\n",
    "    file_sizes_mb = [float(file_size.text) for file_size in file_sizes_mb]\n",
    "    \n",
    "    # Find all the links on the web page\n",
    "    links = soup.find_all('a')\n",
    "    \n",
    "    # Loop through the links to find the files.\n",
    "    files = {}\n",
    "    file_size_i = 0\n",
    "    for link in links:\n",
    "        href = link.get('href')\n",
    "        href = os.path.join(base_url, href.replace('./', ''))\n",
    "        if href.endswith('index.htm'):\n",
    "            # Recursively get files from subdirectories on eumetsat's website\n",
    "            subdir = walk_dir(href.replace('index.htm', ''))\n",
    "            files.update(subdir)\n",
    "        elif href.endswith('.tar'):\n",
    "            files[href] = file_sizes_mb[file_size_i]\n",
    "            file_size_i += 1\n",
    "        elif href.endswith('.pdf'):\n",
    "            files[href] = None\n",
    "    \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = os.environ['EUMETSAT_PASSWORD']\n",
    "url = \"http://jack_kelly:{}@archive.eumetsat.int/umarf/onlinedownload/jack_kelly/\".format(password)\n",
    "log.info('Searching for files to download from %s', url)\n",
    "files = walk_dir(url)\n",
    "files = pd.Series(files, name='filesize_MB')\n",
    "log.info('Found %d files on EUMETSAT website', len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out files which have already been downloaded\n",
    "if os.path.exists(DOWNLOADED_FILES):\n",
    "    with open(DOWNLOADED_FILES, 'r') as fh:\n",
    "        downloaded_files = fh.readlines()\n",
    "    downloaded_files = [filename.strip() for filename in downloaded_files]\n",
    "else:\n",
    "    downloaded_files = []\n",
    "    \n",
    "files_to_download = set(files.index) - set(downloaded_files)\n",
    "files_to_download = files[files_to_download]\n",
    "log.info('%d files still to download.', len(files_to_download))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_queue = queue.Queue()\n",
    "for filename, filesize_mb in files_to_download.items():\n",
    "    filename_queue.put({'filename': filename, 'filesize_mb': filesize_mb})\n",
    "    \n",
    "filename_queue.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, destination_dir='.'):\n",
    "    # Adapted from https://stackoverflow.com/a/16696317/732596\n",
    "    # And alternative pure-Python approach, adapted from https://stackoverflow.com/a/16696317/732596\n",
    "    # uses far more CPU resources than wget.\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.makedirs(destination_dirs)\n",
    "    base_filename = os.path.basename(url)\n",
    "    full_local_filename = os.path.join(destination_dir, base_filename)\n",
    "    if os.path.exists(full_local_filename):\n",
    "        os.remove(full_local_filename)\n",
    "    wget_log_filename = os.path.join(LOG_DIR, base_filename + '.log')\n",
    "    subprocess.run([\n",
    "        'wget', \n",
    "        '--output-file={}'.format(wget_log_filename),\n",
    "        '--no-verbose',  # don't make the log file too verbose\n",
    "        '--tries=16',\n",
    "        # '--continue',  # doesn't work - maybe EUMETSAT aren't providing a 'size' header?\n",
    "        # '--unlink',    # remove file before clobber - doesn't appear to work\n",
    "        '--timeout=300',\n",
    "        '--directory-prefix={}'.format(destination_dir),\n",
    "        url])\n",
    "    return local_filename\n",
    "\n",
    "\n",
    "class DownloadFileSizeMisMatch(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def download_and_check_size(url, destination_dir, expected_filesize_mb, retries=5):\n",
    "    MATCH_TOLERANCE_MEGABYTES = 0.01\n",
    "    for retry in range(retries):\n",
    "        local_filename = download_file(url, destination_dir)\n",
    "        local_filesize_mb = get_filesize_megabytes(local_filename)\n",
    "        if math.isclose(local_filesize_mb, expected_filesize_mb, abs_tol=MATCH_TOLERANCE_MEGABYTES):\n",
    "            return local_filename\n",
    "        else:\n",
    "            log.warn(\n",
    "                'Filesize mismatch!  Try %d of %d.  Expected %.2f MB, got %.2f MB for %s', \n",
    "                retry+1, retries, expected_filesize_mb, local_filesize_mb, url)\n",
    "            \n",
    "    log.error('Filesizes still mismatch after %d tries for %s', retries, url)\n",
    "    raise DownloadFileSizeMisMatch(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_files_lock = threading.Lock()\n",
    "\n",
    "def worker():\n",
    "    while True:\n",
    "        log.info('Files left to download: %d.', filename_queue.qsize())\n",
    "        try:\n",
    "            filename_and_size = filename_queue.get(block=False)\n",
    "        except queue.Empty:\n",
    "            break\n",
    "\n",
    "        remote_filename = filename_and_size['filename']\n",
    "        remote_filesize_mb = filename_and_size['filesize_mb']\n",
    "\n",
    "        log.info('downloading %s', remote_filename)\n",
    "        if remote_filename.endswith('.pdf'):\n",
    "            local_filename = download_file(remote_filename, os.path.join(DESTINATION_DIR, 'shipping_notes'))\n",
    "        elif remote_filename.endswith('.tar'):\n",
    "            log.debug('Expected filesize = %.2f MB', remote_filesize_mb)\n",
    "            local_filename = download_and_check_size(remote_filename, DESTINATION_DIR, remote_filesize_mb)\n",
    "\n",
    "        log.debug('Finished downloading %.2f MB', get_filesize_megabytes(local_filename))\n",
    "        success = downloaded_files_lock.acquire(timeout=60)\n",
    "        if success:\n",
    "            with open(DOWNLOADED_FILES, 'a') as fh:\n",
    "                fh.write('{}\\n'.format(remote_filename))\n",
    "            downloaded_files_lock.release()\n",
    "        else:\n",
    "            log.error('Failed to get lock for DOWNLOAD_FILES table!')\n",
    "            break\n",
    "\n",
    "        filename_queue.task_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []\n",
    "for i in range(NUM_WORKER_THREADS):\n",
    "    t = threading.Thread(target=worker)\n",
    "    t.start()\n",
    "    threads.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for thread in threads:\n",
    "    thread.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
